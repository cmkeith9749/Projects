{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have two new regression methods at your fingertips, it's time to give them a spin. In fact, for this challenge, let's put them together! Pick a dataset of your choice with a binary outcome and the potential for at least 15 features. If you're drawing a blank, the crime rates in 2013 dataset has a lot of variables that could be made into a modelable binary outcome.\n",
    "\n",
    "Engineer your features, then create three models. Each model will be run on a training set and a test-set (or multiple test-sets, if you take a folds approach). The models should be:\n",
    "\n",
    "*Vanilla logistic regression*\n",
    "\n",
    "*Ridge logistic regression*\n",
    "\n",
    "*Lasso logistic regression*\n",
    "\n",
    "If you're stuck on how to begin combining your two new modeling skills, here's a hint: the SKlearn LogisticRegression method has a \"penalty\" argument that takes either 'l1' or 'l2' as a value.\n",
    "\n",
    "In your report, evaluate all three models and decide on your best. Be clear about the decisions you made that led to these models (feature selection, regularization parameter selection, model evaluation criteria) and why you think that particular model is the best of the three. Also reflect on the strengths and limitations of regression as a modeling approach. Were there things you couldn't do but you wish you could have done?\n",
    "\n",
    "Record your work and reflections in a notebook to discuss with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of ‘A-level-geography’\n",
    "\n",
    "The data contain the result of examination on A-level geometry for 33,276 students from over 2,000 institutions in England in 1997. There are 15 fields in the data set of ASCII format, and each field is separated by a blank space. The detailed description of the fields is as followings\n",
    "\n",
    "\n",
    "| Variable  | Coding | Description |\n",
    "| --------- | ------ | ----------- |\n",
    "| SCORE   |   0, 2, 4, 6, 8, 10   | 0=fail, 2=grade E, 4=grade D, 6=grade C, 8=grade B, 10=grade A | \n",
    "| BOARD  | 1 – 7  | 1=Associate and WJB, 2=Cambridge, 3=London, 5=Oxforld, 6=Joint Matriculation, 7=Oxford-Cambridge |\n",
    "| GCSE-G-SCORE | 0,2,3,4,5,6,7,8 | 0=fail, 2=grade F,  3=grade E, 4=grade D, 5=grade C, 6=grade B, 7=grade A, 8=grade A* | \n",
    "| GENDER | 0 or 1 | 0=Male, 1=Female | \t\t\t\n",
    "| GTOT | 19 ~ 95 continuous | \tTotal point score of all GCSE subjects\n",
    "| GNUM | 4 ~13 continuous | \tTotal number of GCSE taken \n",
    "| GCSE-MA-MAX | 0 – 8  | Maximum point score for GCSE math: 0=fail, 2=grade F,  3=grade E, 4=grade D, 5=grade C, 6=grade B, 7=grade A, 8=grade A* | \n",
    "| GCSE-math-n | \t1,2,3,4 | \tTotal number of GCSE math subjects taken | \n",
    "| AGE | \tcontinuous | \tAge of student in month, centred at 222 months ( 18.5 years) | \n",
    "| INST-GA-MN | \tcontinuous | \tInstitution average of GCSE score, centred at its mean | \n",
    "| INST-GA-SD | \tcontinuous | \tInstitution standard deviation of GCSE score | \n",
    "| INSTTYPE\tCategory | 1 ~ 11 |1 = LEA Maintained Comprehensive, 2 = Maintained Selective, 3 = Maintained Modern, 4 = Grammar Comprehensive, 5 = Grammar Selective, 6 = Grammar Modern, 7 = Independent selective, 8 = Independent non-selective, 9 = Sixth Form College, 10 = Further Education College, 11 = Others | \n",
    "| LEA | \t1 ~ 131 | \tLocal Education Authority identification | \n",
    "| INSTITUTE | \t1 ~ 98 | \tInstitution identification within LEA | \n",
    "| STUDENT | \t25 ~ 196053 | \tStudent identification | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "df = pd.read_csv('data/geography.txt', sep=' ', header=None) \n",
    "df.columns = ['a_scre','boards', 'g_ge_s', 'gender', 'g_tl_s', 'g_tl_n','g_m_mx', 'g_m_tl','age_mh',\n",
    "              'i_g_mn', 'i_g_sd','i_type', 'lea_id', 'ise_id', 'studnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_scre</th>\n",
       "      <th>boards</th>\n",
       "      <th>g_ge_s</th>\n",
       "      <th>gender</th>\n",
       "      <th>g_m_mx</th>\n",
       "      <th>g_m_tl</th>\n",
       "      <th>age_mh</th>\n",
       "      <th>i_type</th>\n",
       "      <th>ise_id</th>\n",
       "      <th>passed</th>\n",
       "      <th>g_avg_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33271</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>9</td>\n",
       "      <td>13133</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33272</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>9</td>\n",
       "      <td>13133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33273</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>9</td>\n",
       "      <td>13133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33274</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>227</td>\n",
       "      <td>9</td>\n",
       "      <td>13133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33275</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>9</td>\n",
       "      <td>13133</td>\n",
       "      <td>1</td>\n",
       "      <td>5.3333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a_scre  boards  g_ge_s  gender  g_m_mx  g_m_tl  age_mh  i_type  ise_id  \\\n",
       "33271       8       3       7       1       7       1     219       9   13133   \n",
       "33272       6       3       6       0       6       1     223       9   13133   \n",
       "33273       4       3       5       1       5       1     219       9   13133   \n",
       "33274       8       3       5       1       5       1     227       9   13133   \n",
       "33275       6       3       6       1       5       1     219       9   13133   \n",
       "\n",
       "       passed  g_avg_  \n",
       "33271       1  6.4545  \n",
       "33272       1  5.7778  \n",
       "33273       1  5.1111  \n",
       "33274       1  5.7778  \n",
       "33275       1  5.3333  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new columns and some tranformations\n",
    "df['passed'] = np.where(df.a_scre > 2, 1, 0)\n",
    "df['g_avg_'] = np.round(df.g_tl_s.div(df.g_tl_n), decimals = 4)\n",
    "df.ise_id = df.ise_id.add(df.lea_id * 100)\n",
    "df.ise_id = df.ise_id.apply(lambda x : int(x))\n",
    "df.age_mh = df.age_mh.apply(lambda x : int(x + 222))\n",
    "df.a_scre = df.a_scre.apply(lambda x : int(x))\n",
    "df.i_type = df.i_type.apply(lambda x : int(x))\n",
    "drops = ['studnt', 'lea_id', 'g_tl_s', 'g_tl_n', 'i_g_mn','i_g_sd' ]\n",
    "df = df.drop(drops, axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric Features:\n",
    " - age_mh : int students age in months\n",
    " - g_ge_s : int   students score on lower level geometry test\n",
    " - g_m_mx : int   students best on any lower level math exam\n",
    " - g_m_tl : int   number of lower level math exam student has taken\n",
    " - g_avg_ : float students average score on all lower level exams\n",
    "\n",
    "#### Categorical Features:\n",
    " - i_type : ordinal integers {1:11}  type of institution attended\n",
    " - ise_id : ordinal integers {1:11}  specific institution attended\n",
    " - gender : ordinal integers {0,1}   students, male = 1  \n",
    " - boards : ordinal integers {1, 2, 3, 5, 6, 7, 8}\n",
    "\n",
    "#### Targets\n",
    "- passed : ordinal integers {0, 1}  student passed 1 or failed 0\n",
    "- a_scre : continous int    {0:10}    score awarded for A level geometry exam ==> 0 , 2, 4, 6, 8, or 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop(['passed', 'a_scre'], axis=1)\n",
    "y = df.passed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selector\n",
    "select = SelectKBest(f_regression, k=5)\n",
    "# pipeline appending classifier\n",
    "clf = Pipeline(steps=[('slt', select),\n",
    "                      ('cfr', LogisticRegression(penalty='l1', solver='liblinear', max_iter=200, C=10))])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop(['passed', 'a_scre'], axis=1)\n",
    "y = df.passed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clf_rlr = Pipeline(steps=[('ppr', preprocessor),\n",
    "                      ('slt', select),\n",
    "                      ('cfr', LogisticRegression(penalty='l2', solver='liblinear', max_iter=200, C=10))])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_llr = Pipeline(steps=[('ppr', preprocessor),\n",
    "                      ('slt', select),\n",
    "                      ('cfr', LogisticRegression(penalty='l1', solver='liblinear', max_iter=200, C=10))])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225661057692307\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8168569711538461\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8115985576923077\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls = ['clf_vlr', 'clf_rlr', 'clf_llr']\n",
    "results = []\n",
    "for mdl in mdls:\n",
    "    eval(mdl).fit(X_train, y_train)\n",
    "    y_pred = (eval(mdl)).predict(X_test)\n",
    "    results.append({'score':eval(mdl).score(X_test, y_test), 'mean_abs_error': mean_absolute_error(y_test, y_pred)})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for dct in dcts:\n",
    "    print(dct['cfr__penalty'])\n",
    "    mdl.set_params(**dct)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    print(mdl.score(X_test, y_test))\n",
    "    rst = {'score':mdl.score(X_test, y_test), 'mean_abs_error': mean_absolute_error(y_test, y_pred)}\n",
    "    results.append(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcts = [{'cfr__penalty':'none', 'cfr__solver':'lbfgs'},\n",
    "        {'cfr__penalty':'l2',   'cfr__solver':'lbfgs'},\n",
    "        {'cfr__penalty':'l1',   'cfr__solver':'liblinear'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(X_train, y_train)\n",
    "y_pred = mdl.predict(X_test)\n",
    "print(mdl.score(X_test, y_test))\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8061899038461539\n",
    "0.19381009615384615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.DataFrame([pd.Series(result) for result in results], index=['Vanilla', 'Ridge', 'Lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Pipeline(steps=[('ppr', preprocessor),\n",
    "                      ('slt', select),\n",
    "                      ('cfr', LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_log_proba(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for a,b in param:  \n",
    "    knn1 = neighbors.KNeighborsRegressor(n_neighbors=a, weights=b)\n",
    "    X = music[['loudness', 'duration']]\n",
    "    Y = music.bpm\n",
    "    knn.fit(X, Y)\n",
    "    score = cross_val_score(knn1, X, Y, cv=3)\n",
    "    if b == 'distance': weighted = True\n",
    "    else:               weighted = False\n",
    "    results.append({'n':a,'weighted':weighted,'accuracy':np.round(score.mean(), decimals=2),\n",
    "                    'std':np.round(score.std(), decimals=2)})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.concat([pd.Series(dct) for dct in results], axis=1, sort=False).T    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dfr.pivot(index='n', columns='weighted', values=['accuracy', 'std'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Save predicted values.\n",
    "Y_pred = regr.predict(X)\n",
    "print('R-squared regression:', regr.score(X, y))\n",
    "\n",
    "# Fit a linear model using Partial Least Squares Regression.\n",
    "# Reduce feature space to 3 dimensions.\n",
    "pls1 = PLSRegression(n_components=3)\n",
    "\n",
    "# Reduce X to R(X) and regress on y.\n",
    "pls1.fit(X, y)\n",
    "\n",
    "# Save predicted values.\n",
    "Y_PLS_pred = pls1.predict(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
