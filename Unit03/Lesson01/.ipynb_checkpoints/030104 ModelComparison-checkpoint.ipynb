{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Challenge: Model Comparison\n",
    "\n",
    "You now know two kinds of regression and two kinds of classifier. So let's use that to compare models!\n",
    "\n",
    "Comparing models is something data scientists do all the time. There's very rarely just one model that would be possible to run for a given situation, so learning to choose the best one is very important.\n",
    "\n",
    "Here let's work on regression. Find a data set and build a KNN Regression and an OLS regression. Compare the two. How similar are they? Do they miss in different ways?\n",
    "\n",
    "Create a Jupyter notebook with your models. At the end in a markdown cell write a few paragraphs to describe the models' behaviors and why you favor one model or the other. Try to determine whether there is a situation where you would change your mind, or whether one is unambiguously better than the other. Lastly, try to note what it is about the data that causes the better model to outperform the weaker model. Submit a link to your notebook below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of ‘A-level-geography’\n",
    "\n",
    "The data contain the result of examination on A-level geometry for 33,276 students from over 2,000 institutions in England in 1997. There are 15 fields in the data set of ASCII format, and each field is separated by a blank space. The detailed description of the fields is as followings\n",
    "\n",
    "\n",
    "| Variable  | Coding | Description |\n",
    "| --------- | ------ | ----------- |\n",
    "| SCORE   |   0, 2, 4, 6, 8, 10   | 0=fail, 2=grade E, 4=grade D, 6=grade C, 8=grade B, 10=grade A | \n",
    "| BOARD  | 1 – 7  | 1=Associate and WJB, 2=Cambridge, 3=London, 5=Oxforld, 6=Joint Matriculation, 7=Oxford-Cambridge |\n",
    "| GCSE-G-SCORE | 0,2,3,4,5,6,7,8 | 0=fail, 2=grade F,  3=grade E, 4=grade D, 5=grade C, 6=grade B, 7=grade A, 8=grade A* | \n",
    "| GENDER | 0 or 1 | 0=Male, 1=Female | \t\t\t\n",
    "| GTOT | 19 ~ 95 continuous | \tTotal point score of all GCSE subjects\n",
    "| GNUM | 4 ~13 continuous | \tTotal number of GCSE taken \n",
    "| GCSE-MA-MAX | 0 – 8  | Maximum point score for GCSE math: 0=fail, 2=grade F,  3=grade E, 4=grade D, 5=grade C, 6=grade B, 7=grade A, 8=grade A* | \n",
    "| GCSE-math-n | \t1,2,3,4 | \tTotal number of GCSE math subjects taken | \n",
    "| AGE | \tcontinuous | \tAge of student in month, centred at 222 months ( 18.5 years) | \n",
    "| INST-GA-MN | \tcontinuous | \tInstitution average of GCSE score, centred at its mean | \n",
    "| INST-GA-SD | \tcontinuous | \tInstitution standard deviation of GCSE score | \n",
    "| INSTTYPE\tCategory | 1 ~ 11 |1 = LEA Maintained Comprehensive, 2 = Maintained Selective, 3 = Maintained Modern, 4 = Grammar Comprehensive, 5 = Grammar Selective, 6 = Grammar Modern, 7 = Independent selective, 8 = Independent non-selective, 9 = Sixth Form College, 10 = Further Education College, 11 = Others | \n",
    "| LEA | \t1 ~ 131 | \tLocal Education Authority identification | \n",
    "| INSTITUTE | \t1 ~ 98 | \tInstitution identification within LEA | \n",
    "| STUDENT | \t25 ~ 196053 | \tStudent identification | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_scre</th>\n",
       "      <th>boards</th>\n",
       "      <th>g_ge_s</th>\n",
       "      <th>gender</th>\n",
       "      <th>g_tl_s</th>\n",
       "      <th>g_tl_n</th>\n",
       "      <th>g_m_mx</th>\n",
       "      <th>g_m_tl</th>\n",
       "      <th>age_mh</th>\n",
       "      <th>i_g_mn</th>\n",
       "      <th>i_g_sd</th>\n",
       "      <th>i_type</th>\n",
       "      <th>lea_id</th>\n",
       "      <th>ise_id</th>\n",
       "      <th>studnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33271</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>196035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33272</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>196037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33273</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>196039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33274</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>196047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33275</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>196053.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a_scre  boards  g_ge_s  gender  g_tl_s  g_tl_n  g_m_mx  g_m_tl  age_mh  \\\n",
       "33271     8.0       3       7       1      71    11.0       7       1    -3.0   \n",
       "33272     6.0       3       6       0      52     9.0       6       1     1.0   \n",
       "33273     4.0       3       5       1      46     9.0       5       1    -3.0   \n",
       "33274     8.0       3       5       1      52     9.0       5       1     5.0   \n",
       "33275     6.0       3       6       1      48     9.0       5       1    -3.0   \n",
       "\n",
       "       i_g_mn  i_g_sd  i_type  lea_id  ise_id    studnt  \n",
       "33271   -0.06    0.65     9.0   131.0    33.0  196035.0  \n",
       "33272   -0.06    0.65     9.0   131.0    33.0  196037.0  \n",
       "33273   -0.06    0.65     9.0   131.0    33.0  196039.0  \n",
       "33274   -0.06    0.65     9.0   131.0    33.0  196047.0  \n",
       "33275   -0.06    0.65     9.0   131.0    33.0  196053.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/geography.txt', sep=' ', header=None) \n",
    "df.columns = ['a_scre','boards', 'g_ge_s', 'gender', 'g_tl_s', 'g_tl_n','g_m_mx', 'g_m_tl','age_mh',\n",
    "              'i_g_mn', 'i_g_sd','i_type', 'lea_id', 'ise_id', 'studnt' ]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  {'col1':{'lbl':'col1', 'fnn':'ABC', 'kwg': {}}, 'col2':{}, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops1 = ['i_g_sd', 'studnt']\n",
    "drops2 = ['lea_id', 'g_tl_s', 'g_tl_n', 'i_ga_mn', 'i_ga_sd']\n",
    "df = df.drop(drops1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['passed']                                                             # new ... binary target 1 ==> passing score\n",
    "b = ['g_avg_']                                                             # new ... students average score on gsce math exams\n",
    "c = ['ise_id']                                                             # create unique institue id\n",
    "d = ['age_mh']                                                             # tranform months to continous\n",
    "e = ['board', 'ise_id', 'i_type', 'g_m_tl']                                # rank feature based upon target \n",
    "f = ['board', 'ise_id', 'i_type', 'g_ge_s', 'g_m_mx', 'age_mh', 'g_m_tl']  # linear scale features -2 to 2\n",
    "g = ['g_avg_']                                                             # standardize feature with z score\n",
    "\n",
    "bg  =  list(set(b) & set(g))\n",
    "cef =  list(set(c) & set(e) & set(f))\n",
    "df  =  list(set(d) & set(f)) \n",
    "ef  =  list(set(e) & set(f) - set(cef)) \n",
    "f   =  list(set(f) - set(df) - set(ef) - set(cef))\n",
    "\n",
    "groups = ['bg', 'cef', 'df', 'ef', 'f', 'a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def switch_clean(df, *dict):\\n    for key in dict.keys()\\n        for f in dict[key]['fnn']:\\n            \\n    \\n        df[dict['fte']] = switch[f](df,dict)               \\n    return df\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions to clean or tranform columns\n",
    "def A(df, fte, tgt):\n",
    "    srs = np.where(df[tgt] > 0, 1, 0)\n",
    "    return df\n",
    "def B(df, dict):\n",
    "    df[dict['fte']] = df[dict['cl1']].div(df[dict['cl2']])\n",
    "    return df    \n",
    "def C():  # standardize \n",
    "    z_score = lambda x: (x-x.mean())/x.std()\n",
    "    return S.transform(z_score )    \n",
    "\n",
    "'''\n",
    "def A(S): # tranform to numeric range step 1 for unique values\n",
    "    dct = {S.unique()[i]:i for i in range(len(S.unique()))}\n",
    "    return S.apply(lambda x: dct[x])\n",
    "def B(S):  # standardize \n",
    "    z_score = lambda x: (x-x.mean())/x.std()\n",
    "    return S.transform(z_score )\n",
    "def C(S):  # scale to approx range of -2 to 2\n",
    "    rng = x.max()-x.min()\n",
    "    scale = lambda x: (x- rng/ 2) * 4 / rng\n",
    "    return S.transform(scale)\n",
    "def Z(S):  # dummy function\n",
    "    return S\n",
    "'''\n",
    "switch = {char:eval(char) for char in 'AB'}\n",
    "\n",
    "def switch_clean(df, *dict):\n",
    "    for key in dict.keys()\n",
    "        for f in dict[key]['fnn']:\n",
    "            \n",
    "    \n",
    "        df[dict['fte']] = switch[f](df,dict)               \n",
    "    return df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A() got an unexpected keyword argument 'fnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-2bb3cef63ee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mswitch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mclean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'passed'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: A() got an unexpected keyword argument 'fnn'"
     ]
    }
   ],
   "source": [
    "switch['A'](df, lbl, fnn, kwg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "G\n",
      "C\n",
      "E\n",
      "F\n",
      "D\n",
      "F\n",
      "E\n",
      "F\n",
      "E\n",
      "F\n",
      "E\n",
      "F\n",
      "F\n",
      "F\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "for key in clean.keys():\n",
    "    for f in clean[key]['fnn']:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1c5b50336769>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswitch_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'passed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-69f35fb962e3>\u001b[0m in \u001b[0;36mswitch_clean\u001b[1;34m(df, dict)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mswitch_clean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fnn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fte'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-69f35fb962e3>\u001b[0m in \u001b[0;36mA\u001b[1;34m(df, dict)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tgt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tgt'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "dx = switch_clean(df, clean['passed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'passed'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean['passed']['fte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'passed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f136aae6cf48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpassed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'passed' is not defined"
     ]
    }
   ],
   "source": [
    "df[passed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict \"clean\" with all parameters for switch_clean()\n",
    "dict1 = {val:str.upper(sub) for sub in groups for val in eval(sub)}\n",
    "clean = {key:{'fte':key,'fnn':dict1[key], 'tgt':'a_scre'} for key in dict1.keys()}\n",
    "clean['passed']['cl1'] = 'a_scre'\n",
    "clean['g_avg_']['cl1'] = 'g_tl_s'\n",
    "clean['g_avg_']['cl2'] = 'g_tl_n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary target for passing score\n",
    "df['passd'] = np.where(df.score > 0, 1, 0)\n",
    "# column tranformations to model features\n",
    " \n",
    "df.age = df.age + 222\n",
    "df['inst_id'] = df.lea * 100 + df.institute\n",
    "# to rank feature values to be scaled low to high by 'score'\n",
    "rnk_brd = df.groupby('board').score.mean().sort_values(ascending=True).index\n",
    "rnk_ite = df.groupby('inst_type').score.mean().sort_values(ascending=True).index\n",
    "rnk_iid = df.groupby('inst_id').score.mean().sort_values(ascending=True).index\n",
    "df.board = df.board.apply(lambda x : {rank_brd[i]:i for i in range(len(rank_brd))}[x])\n",
    "# drop columns net needed\n",
    "\n",
    "df = df.drop(drops,axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.g_m_mx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rnk_brd = df.groupby('board').score.mean().sort_values(ascending=True).index\n",
    "rnk_ite = df.groupby('inst_type').score.mean().sort_values(ascending=True).index\n",
    "rnk_iid = df.groupby('inst_id').score.mean().sort_values(ascending=True).index\n",
    "df.board = df.board.apply(lambda x : {rnk_brd[i]:i for i in range(len(rnk_brd))}[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_target(df, tgt, fte):\n",
    "    rnk = df.groupby(fte)[tgt].mean().sort_values(ascending=True).index\n",
    "    dct = {rnk[i]:i for i in range(len(rnk))}\n",
    "    df[fte] = df[fte].apply()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dct2)\n",
    "Y_score = X.score\n",
    "Y_passd = X.passd\n",
    "X = X.drop(['score', 'passd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_passd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "knn_score = neighbors.KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knn_passd = neighbors.KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "knn_score.fit(X, Y_score)\n",
    "knn_passd.fit(X, Y_passd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "acc_score = cross_val_score(knn_score, X, Y_score, cv=5)\n",
    "acc_passd = cross_val_score(knn_passd, X, Y_passd, cv=5)\n",
    "print(\"Predict Score Accuracy: %0.2f (+/- %0.4f)\" % (acc_score.mean(), acc_score.std() ** 2))\n",
    "print(\"Predict passd Accuracy: %0.2f (+/- %0.4f)\" % (acc_passd.mean(),  acc_passd.std()  ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_passd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [(x,y ) for x in range(1,11) for y in ['distance', 'uniform']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for a,b in param:  \n",
    "    knn1 = neighbors.KNeighborsRegressor(n_neighbors=a, weights=b)\n",
    "    X = music[['loudness', 'duration']]\n",
    "    Y = music.bpm\n",
    "    knn.fit(X, Y)\n",
    "    score = cross_val_score(knn1, X, Y, cv=3)\n",
    "    if b == 'distance': weighted = True\n",
    "    else:               weighted = False\n",
    "    results.append({'n':a,'weighted':weighted,'accuracy':np.round(score.mean(), decimals=2),\n",
    "                    'std':np.round(score.std(), decimals=2)})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.concat([pd.Series(dct) for dct in results], axis=1, sort=False).T   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dfr.pivot(index='n', columns='weighted', values=['accuracy', 'std'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Save predicted values.\n",
    "Y_pred = regr.predict(X)\n",
    "print('R-squared regression:', regr.score(X, y))\n",
    "\n",
    "# Fit a linear model using Partial Least Squares Regression.\n",
    "# Reduce feature space to 3 dimensions.\n",
    "pls1 = PLSRegression(n_components=3)\n",
    "\n",
    "# Reduce X to R(X) and regress on y.\n",
    "pls1.fit(X, y)\n",
    "\n",
    "# Save predicted values.\n",
    "Y_PLS_pred = pls1.predict(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
