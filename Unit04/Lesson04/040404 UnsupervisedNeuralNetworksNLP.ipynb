{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to clean text.\n",
    "def text_cleaner(text):\n",
    "    \n",
    "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
    "    # Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    \n",
    "    # Get rid of headings in square brackets.\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    \n",
    "    # Get rid of chapter titles.\n",
    "    text = re.sub(r'Chapter \\d+','',text)\n",
    "    \n",
    "    # Get rid of extra whitespace.\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text[0:900000]\n",
    "\n",
    "\n",
    "# Import all the Austen in the Project Gutenberg corpus.\n",
    "austen = \"\"\n",
    "for novel in ['persuasion','emma','sense']:\n",
    "    work = gutenberg.raw('austen-' + novel + '.txt')\n",
    "    austen = austen + work\n",
    "\n",
    "# Clean the data.\n",
    "austen_clean = text_cleaner(austen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data. This can take some time.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "austen_doc = nlp(austen_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lady', 'russell', 'steady', 'age', 'character', 'extremely', 'provide', 'thought', 'second', 'marriage', 'need', 'apology', 'public', 'apt', 'unreasonably', 'discontent', 'woman', 'marry', 'sir', 'walter', 'continue', 'singleness', 'require', 'explanation']\n",
      "We have 9299 sentences and 900000 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words, and converting words to lower case lemmas.\n",
    "sentences = []\n",
    "for sentence in austen_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(austen_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuck\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Clearly this model is not great â€“ while some words given above might possibly fill in the analogy woman:lady::man:?, most answers likely make little sense. You'll notice as well that re-running the model likely gives you different results, indicating random chance plays a large role here.\n",
    "\n",
    "We do, however, get a nice result on \"marriage\" being dissimilar to \"breakfast\", \"lunch\", and \"dinner\". \n",
    "\n",
    "## Drill 0\n",
    "\n",
    "Take a few minutes to modify the hyperparameters of this model and see how its answers change. Can you wrangle any improvements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "Started checking per the queries above.  Actually \"lunch\" is not in the wv.vocab.  Lunch was not a word in common usage  for the era the book was written so I used \"dining\", but my results were not great.  \n",
    " \n",
    "Checked the words [\"husband\", \"marriage\", \"wife\", \"breakfast\"] and did get the expeected result of \"breakfast\" being dissimilar\n",
    " \n",
    " The most_similar query did not make any sense as a would guess the \"man\" and \"woman\" are very similar words.  I changed mine, but my results were not that much better.\n",
    " \n",
    " The similarity result for \"mr\" and \"mrs\" were consistent for various models and significantly better than the original.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prm =list(ParameterGrid({'window': [3, 6, 9],'size': [100, 200, 300]}))\n",
    "mdl = [word2vec.Word2Vec(sentences,size=prm[i]['size'], window=prm[i]['window']) for i in range(len(prm))]\n",
    "vcb =  mdl[0].wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True True\n"
     ]
    }
   ],
   "source": [
    "check = \"breakfast marriage dinner lunch\".split()\n",
    "check1 = ['lady', 'woman'] + ['man']\n",
    "check2 = ['mr', 'mrs']\n",
    "print(all([c in vcb for c in check]), all([c in vcb for c in check1]), all([c in vcb for c in check1]))\n",
    "check = [\"husband\", \"marriage\", \"wife\", \"breakfast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check using \n",
    "A = []; B = []; C =[]\n",
    "for m in mdl:\n",
    "    sim = [w for w,v in m.wv.most_similar(positive=['lady', 'woman', 'man'])[0:3]]\n",
    "    A.append(sim[0]); B.append(sim[1]); C.append(sim[2])\n",
    "dfs = pd.DataFrame([A,B,C], index=[c for c in 'ABC']).T\n",
    "D = [m.wv.similarity('mr', 'mrs') for m in mdl]\n",
    "dfs['D'] = D\n",
    "E = [m.wv.doesnt_match(check) for m in mdl]\n",
    "dfs['E'] = E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eye</td>\n",
       "      <td>mind</td>\n",
       "      <td>evening</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mind</td>\n",
       "      <td>eye</td>\n",
       "      <td>short</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eye</td>\n",
       "      <td>mind</td>\n",
       "      <td>short</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wish</td>\n",
       "      <td>mind</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short</td>\n",
       "      <td>mind</td>\n",
       "      <td>acquaintance</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>short</td>\n",
       "      <td>receive</td>\n",
       "      <td>feeling</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>sort</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>people</td>\n",
       "      <td>appear</td>\n",
       "      <td>wish</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>feeling</td>\n",
       "      <td>appear</td>\n",
       "      <td>perfectly</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A        B             C      D          E\n",
       "0        eye     mind       evening 0.9989  breakfast\n",
       "1       mind      eye         short 0.9994  breakfast\n",
       "2        eye     mind         short 0.9996  breakfast\n",
       "3       wish     mind          sort 0.9995  breakfast\n",
       "4      short     mind  acquaintance 0.9997  breakfast\n",
       "5      short  receive       feeling 0.9997  breakfast\n",
       "6  perfectly     sort          wish 0.9996  breakfast\n",
       "7     people   appear          wish 0.9998  breakfast\n",
       "8    feeling   appear     perfectly 0.9998  breakfast"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill 1: Word2Vec on 100B+ words\n",
    "\n",
    "As we mentioned, word2vec really works best on a big corpus, but it can take half a day to clean such a corpus and run word2vec on it.  Fortunately, there are word2vec models available that have already been trained on _really_ big corpora. They are big files, but you can download a [pretrained model of your choice here](https://github.com/3Top/word2vec-api). At minimum, the ones built with word2vec (check the \"Architecture\" column) should load smoothly using an appropriately modified version of the code below, and you can play to your heart's content.\n",
    "\n",
    "Because the models are so large, however, you may run into memory problems or crash the kernel. If you can't get a pretrained model to run locally, check out this [interactive web app of the Google News model](https://rare-technologies.com/word2vec-tutorial/#bonus_app) instead.\n",
    "\n",
    "However you access it, play around with a pretrained model. Is there anything interesting you're able to pull out about analogies, similar words, or words that don't match? Write up a quick note about your tinkering and discuss it with your mentor during your next session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the pretrained *interactive web app of the Google News model*  and was disapointed that my name was not in the vocabulary.  Not really, obviously the web app is quite \"inteligent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "96px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
